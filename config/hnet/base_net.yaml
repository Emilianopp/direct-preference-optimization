d_a : 16
alpha : 16
d_A: 256
n_transformer_heads : 4
n_transformer_layers : 8
d_emb : 188
d_hnet : 128
dropout : .0
use_dummies : true 
hnet_forward : true
d_model : null
n_layers : null 